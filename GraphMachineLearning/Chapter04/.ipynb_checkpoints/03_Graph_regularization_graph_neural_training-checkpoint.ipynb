{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Graph Learning and Graph Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will be creating a graph regularized version for a topic classification task. The task is to classify paper depending on their content. However in order to do so, we will also use the information encoded in the citation network that relates documents among each other. Of course, we do know that this kind of information is indeed powerful as papers belonging to the same subject tend to reference each other.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we will be using the Cora dataset available in the stellargraph library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 05:04:41.886742: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 05:04:42.001816: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-08 05:04:42.001833: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-08 05:04:42.641949: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-08 05:04:42.642006: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-08 05:04:42.642012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-08 05:04:43.262715: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-08 05:04:43.262737: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-08 05:04:43.262751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fluid): /proc/driver/nvidia/version does not exist\n",
      "2023-03-08 05:04:43.262967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from stellargraph import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = {\n",
    "      'Case_Based': 0,\n",
    "      'Genetic_Algorithms': 1,\n",
    "      'Neural_Networks': 2,\n",
    "      'Probabilistic_Methods': 3,\n",
    "      'Reinforcement_Learning': 4,\n",
    "      'Rule_Learning': 5,\n",
    "      'Theory': 6,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, labels = dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the Dataset object where we will both include information of the targeted sample (node) and its neighbors. In the following we will also allow to control the number of labelling instances to be used, in order to reproduce and evaluate the classification performance in a semi-supervised setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_extraction, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.train import Example, Features, Feature, Int64List, BytesList, FloatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_PREFIX=\"NL_nbr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(*value):\n",
    "    \"\"\"Returns int64 tf.train.Feature from a bool / enum / int / uint.\"\"\"\n",
    "    return Feature(int64_list=Int64List(value=list(value)))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns bytes tf.train.Feature from a string.\"\"\"\n",
    "    return Feature(\n",
    "        bytes_list=BytesList(value=[value.encode('utf-8')])\n",
    "    )\n",
    "\n",
    "def _float_feature(*value):\n",
    "    return Feature(float_list=FloatList(value=list(value)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "def addFeatures(x, y):\n",
    "    res = Features()\n",
    "    res.CopyFrom(x)\n",
    "    res.MergeFrom(y)\n",
    "    return res\n",
    "\n",
    "def neighborFeatures(features: Features, weight: float, prefix: str):\n",
    "    data = {f\"{prefix}_weight\": _float_feature(weight)}\n",
    "    for name, feature in six.iteritems(features.feature):\n",
    "        data[f\"{prefix}_{name}\"] = feature \n",
    "    return Features(feature=data)\n",
    "\n",
    "def neighborsFeatures(neighbors: List[Tuple[Features, float]]):\n",
    "    return reduce(\n",
    "        addFeatures, \n",
    "        [neighborFeatures(sample, weight, f\"{GRAPH_PREFIX}_{ith}\") for ith, (sample, weight) in enumerate(neighbors)],\n",
    "        Features()\n",
    "    )\n",
    "\n",
    "def getNeighbors(idx, adjMatrix, topn=5):\n",
    "    weights = adjMatrix.loc[idx]\n",
    "    return weights[weights>0].sort_values(ascending=False).head(topn).to_dict()\n",
    "    \n",
    "\n",
    "def semisupervisedDataset(G, labels, ratio=0.2, topn=5):\n",
    "    n = int(np.round(len(labels)*ratio))\n",
    "    \n",
    "    labelled, unlabelled = model_selection.train_test_split(\n",
    "        labels, train_size=n, test_size=None, stratify=labels\n",
    "    )\n",
    "    \n",
    "    adjMatrix = pd.DataFrame.sparse.from_spmatrix(G.to_adjacency_matrix(), index=G.nodes(), columns=G.nodes())\n",
    "    \n",
    "    features = pd.DataFrame(G.node_features(), index=G.nodes())\n",
    "    \n",
    "    dataset = {\n",
    "        index: Features(feature = {\n",
    "            #\"id\": _bytes_feature(str(index)), \n",
    "            \"id\": _int64_feature(index),\n",
    "            \"words\": _float_feature(*[float(x) for x in features.loc[index].values]), \n",
    "            \"label\": _int64_feature(label_index[label])\n",
    "        })\n",
    "        for index, label in pd.concat([labelled, unlabelled]).items()\n",
    "    }\n",
    "    \n",
    "    trainingSet = [\n",
    "        Example(features=addFeatures(\n",
    "            dataset[exampleId], \n",
    "            neighborsFeatures(\n",
    "                [(dataset[nodeId], weight) for nodeId, weight in getNeighbors(exampleId, adjMatrix, topn).items()]\n",
    "            )\n",
    "        ))\n",
    "        for exampleId in labelled.index\n",
    "    ]\n",
    "    \n",
    "    testSet = [Example(features=dataset[exampleId]) for exampleId in unlabelled.index]\n",
    "\n",
    "    serializer = lambda _list: [e.SerializeToString() for e in _list]\n",
    "    \n",
    "    return serializer(trainingSet), serializer(testSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet, testSet = semisupervisedDataset(G, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularySize = 1433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors=2\n",
    "defaultWord = tf.constant(0, dtype=tf.float32, shape=[vocabularySize])\n",
    "\n",
    "def parseExample(example, training=True):\n",
    "    schema = {\n",
    "        'words': tf.io.FixedLenFeature([vocabularySize], tf.float32, default_value=defaultWord),\n",
    "        'label': tf.io.FixedLenFeature((), tf.int64, default_value=-1)\n",
    "    }\n",
    "    \n",
    "    if training is True:\n",
    "        for i in range(neighbors):\n",
    "            name = f\"{GRAPH_PREFIX}_{i}\"\n",
    "            schema[f\"{name}_weight\"] = tf.io.FixedLenFeature([1], tf.float32, default_value=[0.0])\n",
    "            schema[f\"{name}_words\"] = tf.io.FixedLenFeature([vocabularySize], tf.float32, default_value=defaultWord)\n",
    "    \n",
    "    features = tf.io.parse_single_example(example, schema)\n",
    "    \n",
    "    label = features.pop(\"label\")\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jhurtado/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "def sampleGenerator(dataset):\n",
    "    def wrapper():\n",
    "        for example in dataset:\n",
    "            yield example\n",
    "    return wrapper\n",
    "            \n",
    "myTrain = Dataset \\\n",
    "    .from_generator(sampleGenerator(trainingSet), output_types=tf.string, output_shapes=()) \\\n",
    "    .map(lambda x: parseExample(x, True))\n",
    "\n",
    "myTest = Dataset \\\n",
    "    .from_generator(sampleGenerator(testSet), output_types=tf.string, output_shapes=()) \\\n",
    "    .map(lambda x: parseExample(x, False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NL_nbr_0_weight': <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [2.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [2.],\n",
      "       [1.]], dtype=float32)>, 'NL_nbr_0_words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, 'NL_nbr_1_weight': <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[0.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [2.],\n",
      "       [1.]], dtype=float32)>, 'NL_nbr_1_words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, 'words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}\n",
      "tf.Tensor([0 0 0 5 2 4 2 3 1 2], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for features, labels in myTrain.batch(10).take(1):\n",
    "    print(features)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}\n",
      "tf.Tensor([1 0 1 6 3 2 3 2 3 2], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for features, labels in myTest.batch(10).take(1):\n",
    "    print(features)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the model that we will use to classify the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [50, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creates a functional API-based multi-layer perceptron model.\"\"\"\n",
    "def create_model(num_units):\n",
    "    inputs = tf.keras.Input(\n",
    "          shape=(vocabularySize,), dtype='float32', name='words'\n",
    "    )\n",
    "\n",
    "    # outputs = tf.keras.layers.Dense(len(label_index), activation='softmax')(inputs)\n",
    "\n",
    "    cur_layer =  inputs\n",
    "\n",
    "    for num_units in layers:\n",
    "        cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n",
    "        cur_layer = tf.keras.layers.Dropout(0.8)(cur_layer)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(len(label_index), activation='softmax')(cur_layer)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train a simple, vanilla version that does not use the citation network information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model([50, 50])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " words (InputLayer)          [(None, 1433)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                71700     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,607\n",
      "Trainable params: 74,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhurtado/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['NL_nbr_0_weight', 'NL_nbr_0_words', 'NL_nbr_1_weight', 'NL_nbr_1_words'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 120ms/step - loss: 2.0874 - accuracy: 0.1292 - val_loss: 1.9606 - val_accuracy: 0.0933\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 2.0690 - accuracy: 0.1384 - val_loss: 1.9473 - val_accuracy: 0.1302\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 2.0468 - accuracy: 0.1513 - val_loss: 1.9370 - val_accuracy: 0.1681\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.0117 - accuracy: 0.1402 - val_loss: 1.9291 - val_accuracy: 0.2262\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.9515 - accuracy: 0.1753 - val_loss: 1.9226 - val_accuracy: 0.2733\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.9342 - accuracy: 0.1808 - val_loss: 1.9168 - val_accuracy: 0.2982\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.9074 - accuracy: 0.2177 - val_loss: 1.9113 - val_accuracy: 0.3149\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.9258 - accuracy: 0.2417 - val_loss: 1.9059 - val_accuracy: 0.3153\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.9261 - accuracy: 0.2214 - val_loss: 1.9006 - val_accuracy: 0.3181\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.9337 - accuracy: 0.2362 - val_loss: 1.8959 - val_accuracy: 0.3190\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.8981 - accuracy: 0.2232 - val_loss: 1.8915 - val_accuracy: 0.3190\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.8858 - accuracy: 0.2417 - val_loss: 1.8865 - val_accuracy: 0.3186\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.8720 - accuracy: 0.2454 - val_loss: 1.8811 - val_accuracy: 0.3163\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.8784 - accuracy: 0.2399 - val_loss: 1.8761 - val_accuracy: 0.3130\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.8960 - accuracy: 0.2251 - val_loss: 1.8715 - val_accuracy: 0.3112\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.8714 - accuracy: 0.2565 - val_loss: 1.8662 - val_accuracy: 0.3102\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.8687 - accuracy: 0.2712 - val_loss: 1.8608 - val_accuracy: 0.3098\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.8637 - accuracy: 0.2620 - val_loss: 1.8554 - val_accuracy: 0.3093\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.8715 - accuracy: 0.2528 - val_loss: 1.8502 - val_accuracy: 0.3093\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.8330 - accuracy: 0.2878 - val_loss: 1.8453 - val_accuracy: 0.3089\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.8207 - accuracy: 0.2952 - val_loss: 1.8395 - val_accuracy: 0.3089\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.8284 - accuracy: 0.2749 - val_loss: 1.8340 - val_accuracy: 0.3093\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.8484 - accuracy: 0.2878 - val_loss: 1.8293 - val_accuracy: 0.3093\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.7918 - accuracy: 0.2989 - val_loss: 1.8240 - val_accuracy: 0.3093\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.7962 - accuracy: 0.2915 - val_loss: 1.8180 - val_accuracy: 0.3102\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.8093 - accuracy: 0.3007 - val_loss: 1.8123 - val_accuracy: 0.3112\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.7892 - accuracy: 0.3026 - val_loss: 1.8067 - val_accuracy: 0.3107\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.7744 - accuracy: 0.2970 - val_loss: 1.8003 - val_accuracy: 0.3116\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7938 - accuracy: 0.2934 - val_loss: 1.7930 - val_accuracy: 0.3126\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.7556 - accuracy: 0.3303 - val_loss: 1.7866 - val_accuracy: 0.3126\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.7669 - accuracy: 0.2934 - val_loss: 1.7803 - val_accuracy: 0.3149\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.7335 - accuracy: 0.3303 - val_loss: 1.7740 - val_accuracy: 0.3181\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.7502 - accuracy: 0.3229 - val_loss: 1.7678 - val_accuracy: 0.3213\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.7149 - accuracy: 0.3376 - val_loss: 1.7628 - val_accuracy: 0.3269\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.7674 - accuracy: 0.2952 - val_loss: 1.7571 - val_accuracy: 0.3319\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7381 - accuracy: 0.3266 - val_loss: 1.7506 - val_accuracy: 0.3333\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.6966 - accuracy: 0.3542 - val_loss: 1.7428 - val_accuracy: 0.3333\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.6927 - accuracy: 0.3247 - val_loss: 1.7343 - val_accuracy: 0.3338\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.6731 - accuracy: 0.3469 - val_loss: 1.7254 - val_accuracy: 0.3347\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7010 - accuracy: 0.3229 - val_loss: 1.7173 - val_accuracy: 0.3370\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.6647 - accuracy: 0.3653 - val_loss: 1.7094 - val_accuracy: 0.3407\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.6604 - accuracy: 0.3432 - val_loss: 1.7009 - val_accuracy: 0.3458\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.6638 - accuracy: 0.3247 - val_loss: 1.6919 - val_accuracy: 0.3495\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.6432 - accuracy: 0.3598 - val_loss: 1.6836 - val_accuracy: 0.3532\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.6405 - accuracy: 0.3487 - val_loss: 1.6762 - val_accuracy: 0.3592\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.6280 - accuracy: 0.3561 - val_loss: 1.6697 - val_accuracy: 0.3675\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.6099 - accuracy: 0.3598 - val_loss: 1.6631 - val_accuracy: 0.3744\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.6061 - accuracy: 0.3561 - val_loss: 1.6543 - val_accuracy: 0.3837\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.6036 - accuracy: 0.3893 - val_loss: 1.6456 - val_accuracy: 0.3915\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.5685 - accuracy: 0.3856 - val_loss: 1.6359 - val_accuracy: 0.3984\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.6040 - accuracy: 0.3432 - val_loss: 1.6266 - val_accuracy: 0.4007\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.5971 - accuracy: 0.3524 - val_loss: 1.6188 - val_accuracy: 0.4044\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.5601 - accuracy: 0.3856 - val_loss: 1.6111 - val_accuracy: 0.4104\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.5499 - accuracy: 0.3727 - val_loss: 1.6046 - val_accuracy: 0.4178\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.5472 - accuracy: 0.3911 - val_loss: 1.5981 - val_accuracy: 0.4271\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.5297 - accuracy: 0.3745 - val_loss: 1.5914 - val_accuracy: 0.4377\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.5142 - accuracy: 0.3856 - val_loss: 1.5830 - val_accuracy: 0.4464\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.5241 - accuracy: 0.3930 - val_loss: 1.5741 - val_accuracy: 0.4511\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.4980 - accuracy: 0.4151 - val_loss: 1.5652 - val_accuracy: 0.4506\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.5585 - accuracy: 0.3579 - val_loss: 1.5574 - val_accuracy: 0.4529\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.4930 - accuracy: 0.3856 - val_loss: 1.5507 - val_accuracy: 0.4557\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.4808 - accuracy: 0.4151 - val_loss: 1.5450 - val_accuracy: 0.4612\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4888 - accuracy: 0.4022 - val_loss: 1.5392 - val_accuracy: 0.4649\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.4948 - accuracy: 0.3967 - val_loss: 1.5335 - val_accuracy: 0.4755\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.4339 - accuracy: 0.4280 - val_loss: 1.5286 - val_accuracy: 0.4829\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.4459 - accuracy: 0.4059 - val_loss: 1.5223 - val_accuracy: 0.4880\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4678 - accuracy: 0.4059 - val_loss: 1.5163 - val_accuracy: 0.4898\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.4412 - accuracy: 0.4170 - val_loss: 1.5095 - val_accuracy: 0.4954\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.4459 - accuracy: 0.4133 - val_loss: 1.5034 - val_accuracy: 0.4982\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.4141 - accuracy: 0.4373 - val_loss: 1.4979 - val_accuracy: 0.4958\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.4019 - accuracy: 0.4465 - val_loss: 1.4912 - val_accuracy: 0.4968\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.3768 - accuracy: 0.4354 - val_loss: 1.4829 - val_accuracy: 0.4982\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.3722 - accuracy: 0.4557 - val_loss: 1.4751 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.4221 - accuracy: 0.4225 - val_loss: 1.4683 - val_accuracy: 0.5023\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.3482 - accuracy: 0.4649 - val_loss: 1.4619 - val_accuracy: 0.5042\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.3952 - accuracy: 0.4114 - val_loss: 1.4553 - val_accuracy: 0.5074\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.3526 - accuracy: 0.4446 - val_loss: 1.4488 - val_accuracy: 0.5092\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.3211 - accuracy: 0.4705 - val_loss: 1.4428 - val_accuracy: 0.5106\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.3315 - accuracy: 0.4262 - val_loss: 1.4368 - val_accuracy: 0.5115\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.3026 - accuracy: 0.4520 - val_loss: 1.4306 - val_accuracy: 0.5148\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.2614 - accuracy: 0.4779 - val_loss: 1.4241 - val_accuracy: 0.5185\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.3276 - accuracy: 0.4723 - val_loss: 1.4179 - val_accuracy: 0.5217\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.2928 - accuracy: 0.4613 - val_loss: 1.4113 - val_accuracy: 0.5249\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.2858 - accuracy: 0.4686 - val_loss: 1.4051 - val_accuracy: 0.5277\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.2752 - accuracy: 0.4889 - val_loss: 1.3991 - val_accuracy: 0.5295\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.2507 - accuracy: 0.5055 - val_loss: 1.3935 - val_accuracy: 0.5286\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.2524 - accuracy: 0.5203 - val_loss: 1.3877 - val_accuracy: 0.5309\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.2182 - accuracy: 0.5240 - val_loss: 1.3820 - val_accuracy: 0.5295\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.2222 - accuracy: 0.5221 - val_loss: 1.3775 - val_accuracy: 0.5314\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.2656 - accuracy: 0.4908 - val_loss: 1.3726 - val_accuracy: 0.5300\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.2301 - accuracy: 0.5258 - val_loss: 1.3672 - val_accuracy: 0.5342\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.2187 - accuracy: 0.5111 - val_loss: 1.3619 - val_accuracy: 0.5337\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.2146 - accuracy: 0.5148 - val_loss: 1.3575 - val_accuracy: 0.5369\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.2593 - accuracy: 0.5018 - val_loss: 1.3534 - val_accuracy: 0.5416\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.2657 - accuracy: 0.5018 - val_loss: 1.3490 - val_accuracy: 0.5429\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.2261 - accuracy: 0.5185 - val_loss: 1.3451 - val_accuracy: 0.5434\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.2161 - accuracy: 0.5314 - val_loss: 1.3414 - val_accuracy: 0.5443\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.1540 - accuracy: 0.5720 - val_loss: 1.3378 - val_accuracy: 0.5476\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.1186 - accuracy: 0.5793 - val_loss: 1.3342 - val_accuracy: 0.5494\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.1734 - accuracy: 0.5480 - val_loss: 1.3305 - val_accuracy: 0.5526\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.1695 - accuracy: 0.5683 - val_loss: 1.3269 - val_accuracy: 0.5572\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.1215 - accuracy: 0.6089 - val_loss: 1.3236 - val_accuracy: 0.5577\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.1774 - accuracy: 0.5627 - val_loss: 1.3217 - val_accuracy: 0.5563\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.1203 - accuracy: 0.5941 - val_loss: 1.3205 - val_accuracy: 0.5582\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.1927 - accuracy: 0.5351 - val_loss: 1.3199 - val_accuracy: 0.5586\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0940 - accuracy: 0.5830 - val_loss: 1.3181 - val_accuracy: 0.5582\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.1096 - accuracy: 0.5793 - val_loss: 1.3136 - val_accuracy: 0.5623\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.1538 - accuracy: 0.5554 - val_loss: 1.3095 - val_accuracy: 0.5633\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.0987 - accuracy: 0.5867 - val_loss: 1.3053 - val_accuracy: 0.5651\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.1419 - accuracy: 0.5480 - val_loss: 1.3022 - val_accuracy: 0.5660\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.1025 - accuracy: 0.5793 - val_loss: 1.3013 - val_accuracy: 0.5679\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0674 - accuracy: 0.5978 - val_loss: 1.3007 - val_accuracy: 0.5679\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.0835 - accuracy: 0.5886 - val_loss: 1.3004 - val_accuracy: 0.5697\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0862 - accuracy: 0.6144 - val_loss: 1.2990 - val_accuracy: 0.5716\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.0974 - accuracy: 0.5756 - val_loss: 1.2986 - val_accuracy: 0.5734\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.0600 - accuracy: 0.6181 - val_loss: 1.2986 - val_accuracy: 0.5757\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0559 - accuracy: 0.6236 - val_loss: 1.2981 - val_accuracy: 0.5762\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.0582 - accuracy: 0.6181 - val_loss: 1.2978 - val_accuracy: 0.5780\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9987 - accuracy: 0.6476 - val_loss: 1.2974 - val_accuracy: 0.5789\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.0236 - accuracy: 0.6236 - val_loss: 1.2961 - val_accuracy: 0.5799\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0602 - accuracy: 0.6125 - val_loss: 1.2947 - val_accuracy: 0.5785\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0272 - accuracy: 0.6347 - val_loss: 1.2914 - val_accuracy: 0.5813\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0121 - accuracy: 0.6199 - val_loss: 1.2880 - val_accuracy: 0.5826\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.0596 - accuracy: 0.5959 - val_loss: 1.2855 - val_accuracy: 0.5849\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9841 - accuracy: 0.6384 - val_loss: 1.2839 - val_accuracy: 0.5891\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.0713 - accuracy: 0.6089 - val_loss: 1.2850 - val_accuracy: 0.5886\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0359 - accuracy: 0.6199 - val_loss: 1.2877 - val_accuracy: 0.5896\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.9878 - accuracy: 0.6384 - val_loss: 1.2902 - val_accuracy: 0.5910\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0062 - accuracy: 0.6421 - val_loss: 1.2908 - val_accuracy: 0.5928\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.9896 - accuracy: 0.6494 - val_loss: 1.2882 - val_accuracy: 0.5923\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9731 - accuracy: 0.6587 - val_loss: 1.2864 - val_accuracy: 0.5933\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9812 - accuracy: 0.6310 - val_loss: 1.2848 - val_accuracy: 0.5951\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.0192 - accuracy: 0.6384 - val_loss: 1.2845 - val_accuracy: 0.5974\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.9806 - accuracy: 0.6328 - val_loss: 1.2867 - val_accuracy: 0.5983\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9812 - accuracy: 0.6587 - val_loss: 1.2882 - val_accuracy: 0.6002\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0111 - accuracy: 0.6328 - val_loss: 1.2909 - val_accuracy: 0.6034\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.9424 - accuracy: 0.6624 - val_loss: 1.2920 - val_accuracy: 0.6043\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.9644 - accuracy: 0.6347 - val_loss: 1.2928 - val_accuracy: 0.6048\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.9541 - accuracy: 0.6384 - val_loss: 1.2937 - val_accuracy: 0.6057\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.9378 - accuracy: 0.6494 - val_loss: 1.2949 - val_accuracy: 0.6080\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9336 - accuracy: 0.6550 - val_loss: 1.2993 - val_accuracy: 0.6076\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.9627 - accuracy: 0.6494 - val_loss: 1.3055 - val_accuracy: 0.6076\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.9476 - accuracy: 0.6642 - val_loss: 1.3124 - val_accuracy: 0.6062\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9555 - accuracy: 0.6439 - val_loss: 1.3167 - val_accuracy: 0.6057\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9557 - accuracy: 0.6605 - val_loss: 1.3193 - val_accuracy: 0.6062\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.9793 - accuracy: 0.6328 - val_loss: 1.3219 - val_accuracy: 0.6043\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9473 - accuracy: 0.6531 - val_loss: 1.3221 - val_accuracy: 0.6053\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9510 - accuracy: 0.6494 - val_loss: 1.3202 - val_accuracy: 0.6062\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9152 - accuracy: 0.6716 - val_loss: 1.3201 - val_accuracy: 0.6066\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9155 - accuracy: 0.6679 - val_loss: 1.3208 - val_accuracy: 0.6062\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9099 - accuracy: 0.6624 - val_loss: 1.3208 - val_accuracy: 0.6071\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.9005 - accuracy: 0.6642 - val_loss: 1.3212 - val_accuracy: 0.6090\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8686 - accuracy: 0.6974 - val_loss: 1.3249 - val_accuracy: 0.6094\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.9101 - accuracy: 0.6716 - val_loss: 1.3283 - val_accuracy: 0.6117\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8960 - accuracy: 0.6716 - val_loss: 1.3295 - val_accuracy: 0.6108\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.9546 - accuracy: 0.6642 - val_loss: 1.3242 - val_accuracy: 0.6154\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8943 - accuracy: 0.6753 - val_loss: 1.3197 - val_accuracy: 0.6177\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8589 - accuracy: 0.6790 - val_loss: 1.3175 - val_accuracy: 0.6182\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8648 - accuracy: 0.7030 - val_loss: 1.3185 - val_accuracy: 0.6187\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8721 - accuracy: 0.6697 - val_loss: 1.3198 - val_accuracy: 0.6196\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.9272 - accuracy: 0.6716 - val_loss: 1.3229 - val_accuracy: 0.6187\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8910 - accuracy: 0.6697 - val_loss: 1.3290 - val_accuracy: 0.6182\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8946 - accuracy: 0.6716 - val_loss: 1.3347 - val_accuracy: 0.6182\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.9172 - accuracy: 0.6753 - val_loss: 1.3427 - val_accuracy: 0.6177\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8750 - accuracy: 0.6900 - val_loss: 1.3490 - val_accuracy: 0.6168\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8842 - accuracy: 0.6679 - val_loss: 1.3536 - val_accuracy: 0.6154\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8680 - accuracy: 0.6790 - val_loss: 1.3576 - val_accuracy: 0.6145\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8133 - accuracy: 0.7048 - val_loss: 1.3624 - val_accuracy: 0.6150\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8385 - accuracy: 0.7177 - val_loss: 1.3650 - val_accuracy: 0.6154\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8944 - accuracy: 0.6697 - val_loss: 1.3655 - val_accuracy: 0.6163\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8558 - accuracy: 0.6937 - val_loss: 1.3633 - val_accuracy: 0.6214\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8722 - accuracy: 0.6863 - val_loss: 1.3652 - val_accuracy: 0.6214\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8641 - accuracy: 0.6956 - val_loss: 1.3628 - val_accuracy: 0.6219\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7970 - accuracy: 0.7196 - val_loss: 1.3640 - val_accuracy: 0.6233\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8867 - accuracy: 0.6679 - val_loss: 1.3669 - val_accuracy: 0.6228\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9053 - accuracy: 0.6734 - val_loss: 1.3699 - val_accuracy: 0.6233\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8091 - accuracy: 0.7103 - val_loss: 1.3742 - val_accuracy: 0.6233\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8015 - accuracy: 0.7232 - val_loss: 1.3780 - val_accuracy: 0.6242\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8868 - accuracy: 0.6808 - val_loss: 1.3798 - val_accuracy: 0.6242\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8755 - accuracy: 0.6531 - val_loss: 1.3795 - val_accuracy: 0.6260\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8274 - accuracy: 0.7048 - val_loss: 1.3795 - val_accuracy: 0.6274\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8333 - accuracy: 0.7066 - val_loss: 1.3815 - val_accuracy: 0.6256\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7959 - accuracy: 0.7103 - val_loss: 1.3878 - val_accuracy: 0.6256\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8162 - accuracy: 0.6974 - val_loss: 1.3948 - val_accuracy: 0.6247\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8042 - accuracy: 0.6937 - val_loss: 1.4019 - val_accuracy: 0.6256\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8435 - accuracy: 0.7066 - val_loss: 1.4027 - val_accuracy: 0.6265\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7877 - accuracy: 0.7196 - val_loss: 1.4032 - val_accuracy: 0.6260\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8204 - accuracy: 0.6956 - val_loss: 1.4064 - val_accuracy: 0.6270\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.8245 - accuracy: 0.7085 - val_loss: 1.4137 - val_accuracy: 0.6288\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8389 - accuracy: 0.6882 - val_loss: 1.4189 - val_accuracy: 0.6279\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8482 - accuracy: 0.6771 - val_loss: 1.4196 - val_accuracy: 0.6283\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7850 - accuracy: 0.7214 - val_loss: 1.4223 - val_accuracy: 0.6311\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8339 - accuracy: 0.6808 - val_loss: 1.4238 - val_accuracy: 0.6334\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7928 - accuracy: 0.7066 - val_loss: 1.4262 - val_accuracy: 0.6334\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8144 - accuracy: 0.6993 - val_loss: 1.4284 - val_accuracy: 0.6320\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7932 - accuracy: 0.7048 - val_loss: 1.4282 - val_accuracy: 0.6330\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8115 - accuracy: 0.7030 - val_loss: 1.4293 - val_accuracy: 0.6330\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8147 - accuracy: 0.6956 - val_loss: 1.4277 - val_accuracy: 0.6343\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7660 - accuracy: 0.7232 - val_loss: 1.4244 - val_accuracy: 0.6357\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7963 - accuracy: 0.7066 - val_loss: 1.4294 - val_accuracy: 0.6353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79b06b9cd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(myTrain.batch(128), epochs=200, verbose=1, validation_data=myTest.batch(128),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/noRegularization')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Regularized Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the graph-regularized version that uses the citation network information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = create_model([50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_structured_learning as nsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_reg_config = nsl.configs.make_graph_reg_config(\n",
    "    max_neighbors=2,\n",
    "    multiplier=0.1,\n",
    "    distance_type=nsl.configs.DistanceType.L2,\n",
    "    sum_over_axis=-1)\n",
    "graph_reg_model = nsl.keras.GraphRegularization(base_model,\n",
    "                                                graph_reg_config)\n",
    "graph_reg_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "#graph_reg_model.fit(train_dataset, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 86ms/step - loss: 2.0522 - accuracy: 0.1605 - scaled_graph_loss: 0.0059 - val_loss: 1.9305 - val_accuracy: 0.2165\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.9914 - accuracy: 0.1513 - scaled_graph_loss: 0.0052 - val_loss: 1.9218 - val_accuracy: 0.2553\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.9517 - accuracy: 0.1974 - scaled_graph_loss: 0.0044 - val_loss: 1.9146 - val_accuracy: 0.2742\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.9746 - accuracy: 0.1642 - scaled_graph_loss: 0.0041 - val_loss: 1.9079 - val_accuracy: 0.2881\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.9632 - accuracy: 0.1753 - scaled_graph_loss: 0.0039 - val_loss: 1.9023 - val_accuracy: 0.3010\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.9333 - accuracy: 0.1937 - scaled_graph_loss: 0.0036 - val_loss: 1.8977 - val_accuracy: 0.3089\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.9177 - accuracy: 0.2251 - scaled_graph_loss: 0.0034 - val_loss: 1.8930 - val_accuracy: 0.3093\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 1.8853 - accuracy: 0.2435 - scaled_graph_loss: 0.0033 - val_loss: 1.8880 - val_accuracy: 0.3079\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.8957 - accuracy: 0.2362 - scaled_graph_loss: 0.0031 - val_loss: 1.8830 - val_accuracy: 0.3066\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.8854 - accuracy: 0.2306 - scaled_graph_loss: 0.0033 - val_loss: 1.8782 - val_accuracy: 0.3038\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.8799 - accuracy: 0.2417 - scaled_graph_loss: 0.0032 - val_loss: 1.8734 - val_accuracy: 0.3015\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.8537 - accuracy: 0.2601 - scaled_graph_loss: 0.0033 - val_loss: 1.8685 - val_accuracy: 0.3024\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.8626 - accuracy: 0.2786 - scaled_graph_loss: 0.0033 - val_loss: 1.8634 - val_accuracy: 0.3029\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.8769 - accuracy: 0.2435 - scaled_graph_loss: 0.0035 - val_loss: 1.8587 - val_accuracy: 0.3029\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.8436 - accuracy: 0.2768 - scaled_graph_loss: 0.0038 - val_loss: 1.8540 - val_accuracy: 0.3024\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.8500 - accuracy: 0.2620 - scaled_graph_loss: 0.0035 - val_loss: 1.8492 - val_accuracy: 0.3029\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.8413 - accuracy: 0.2712 - scaled_graph_loss: 0.0041 - val_loss: 1.8442 - val_accuracy: 0.3029\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.8398 - accuracy: 0.2804 - scaled_graph_loss: 0.0040 - val_loss: 1.8398 - val_accuracy: 0.3029\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.8320 - accuracy: 0.2583 - scaled_graph_loss: 0.0035 - val_loss: 1.8347 - val_accuracy: 0.3033\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.8210 - accuracy: 0.2823 - scaled_graph_loss: 0.0045 - val_loss: 1.8293 - val_accuracy: 0.3033\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.8014 - accuracy: 0.2878 - scaled_graph_loss: 0.0042 - val_loss: 1.8236 - val_accuracy: 0.3033\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.7963 - accuracy: 0.2841 - scaled_graph_loss: 0.0045 - val_loss: 1.8173 - val_accuracy: 0.3038\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.8013 - accuracy: 0.2970 - scaled_graph_loss: 0.0049 - val_loss: 1.8109 - val_accuracy: 0.3042\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.7808 - accuracy: 0.3173 - scaled_graph_loss: 0.0052 - val_loss: 1.8049 - val_accuracy: 0.3066\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.7654 - accuracy: 0.3007 - scaled_graph_loss: 0.0055 - val_loss: 1.7982 - val_accuracy: 0.3089\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.7694 - accuracy: 0.3044 - scaled_graph_loss: 0.0058 - val_loss: 1.7916 - val_accuracy: 0.3112\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7715 - accuracy: 0.2694 - scaled_graph_loss: 0.0055 - val_loss: 1.7849 - val_accuracy: 0.3135\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.7487 - accuracy: 0.3026 - scaled_graph_loss: 0.0057 - val_loss: 1.7785 - val_accuracy: 0.3153\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7296 - accuracy: 0.3155 - scaled_graph_loss: 0.0062 - val_loss: 1.7723 - val_accuracy: 0.3218\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.7264 - accuracy: 0.2841 - scaled_graph_loss: 0.0067 - val_loss: 1.7661 - val_accuracy: 0.3250\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7415 - accuracy: 0.3063 - scaled_graph_loss: 0.0062 - val_loss: 1.7592 - val_accuracy: 0.3269\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.7082 - accuracy: 0.3284 - scaled_graph_loss: 0.0068 - val_loss: 1.7520 - val_accuracy: 0.3287\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.7163 - accuracy: 0.3137 - scaled_graph_loss: 0.0078 - val_loss: 1.7451 - val_accuracy: 0.3329\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.6653 - accuracy: 0.3579 - scaled_graph_loss: 0.0077 - val_loss: 1.7372 - val_accuracy: 0.3366\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.6830 - accuracy: 0.3210 - scaled_graph_loss: 0.0076 - val_loss: 1.7294 - val_accuracy: 0.3403\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.7100 - accuracy: 0.3044 - scaled_graph_loss: 0.0080 - val_loss: 1.7214 - val_accuracy: 0.3476\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.7042 - accuracy: 0.3118 - scaled_graph_loss: 0.0074 - val_loss: 1.7147 - val_accuracy: 0.3541\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.6498 - accuracy: 0.3469 - scaled_graph_loss: 0.0083 - val_loss: 1.7078 - val_accuracy: 0.3592\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.6621 - accuracy: 0.3358 - scaled_graph_loss: 0.0088 - val_loss: 1.7002 - val_accuracy: 0.3638\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.6456 - accuracy: 0.3487 - scaled_graph_loss: 0.0078 - val_loss: 1.6931 - val_accuracy: 0.3675\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.6810 - accuracy: 0.3044 - scaled_graph_loss: 0.0075 - val_loss: 1.6852 - val_accuracy: 0.3721\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.6557 - accuracy: 0.3506 - scaled_graph_loss: 0.0094 - val_loss: 1.6779 - val_accuracy: 0.3753\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.6372 - accuracy: 0.3376 - scaled_graph_loss: 0.0106 - val_loss: 1.6722 - val_accuracy: 0.3818\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.6074 - accuracy: 0.3450 - scaled_graph_loss: 0.0103 - val_loss: 1.6661 - val_accuracy: 0.3841\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.6115 - accuracy: 0.3395 - scaled_graph_loss: 0.0117 - val_loss: 1.6595 - val_accuracy: 0.3855\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.5906 - accuracy: 0.3542 - scaled_graph_loss: 0.0104 - val_loss: 1.6519 - val_accuracy: 0.3883\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.5754 - accuracy: 0.3782 - scaled_graph_loss: 0.0096 - val_loss: 1.6431 - val_accuracy: 0.3947\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.5683 - accuracy: 0.3727 - scaled_graph_loss: 0.0132 - val_loss: 1.6335 - val_accuracy: 0.4012\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 1.5492 - accuracy: 0.3653 - scaled_graph_loss: 0.0117 - val_loss: 1.6242 - val_accuracy: 0.4044\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.5652 - accuracy: 0.3616 - scaled_graph_loss: 0.0117 - val_loss: 1.6154 - val_accuracy: 0.4063\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.5529 - accuracy: 0.3579 - scaled_graph_loss: 0.0124 - val_loss: 1.6081 - val_accuracy: 0.4081\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.5532 - accuracy: 0.3635 - scaled_graph_loss: 0.0120 - val_loss: 1.6002 - val_accuracy: 0.4095\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4969 - accuracy: 0.3708 - scaled_graph_loss: 0.0134 - val_loss: 1.5930 - val_accuracy: 0.4109\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.5341 - accuracy: 0.3690 - scaled_graph_loss: 0.0126 - val_loss: 1.5854 - val_accuracy: 0.4118\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.5081 - accuracy: 0.3727 - scaled_graph_loss: 0.0137 - val_loss: 1.5784 - val_accuracy: 0.4123\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.5244 - accuracy: 0.3690 - scaled_graph_loss: 0.0126 - val_loss: 1.5709 - val_accuracy: 0.4132\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4963 - accuracy: 0.3801 - scaled_graph_loss: 0.0126 - val_loss: 1.5620 - val_accuracy: 0.4151\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.5150 - accuracy: 0.3708 - scaled_graph_loss: 0.0127 - val_loss: 1.5527 - val_accuracy: 0.4169\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.4958 - accuracy: 0.3598 - scaled_graph_loss: 0.0144 - val_loss: 1.5440 - val_accuracy: 0.4187\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4742 - accuracy: 0.3727 - scaled_graph_loss: 0.0141 - val_loss: 1.5360 - val_accuracy: 0.4183\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.4825 - accuracy: 0.3838 - scaled_graph_loss: 0.0145 - val_loss: 1.5285 - val_accuracy: 0.4206\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4620 - accuracy: 0.3930 - scaled_graph_loss: 0.0150 - val_loss: 1.5222 - val_accuracy: 0.4234\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4353 - accuracy: 0.3967 - scaled_graph_loss: 0.0145 - val_loss: 1.5148 - val_accuracy: 0.4266\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4138 - accuracy: 0.4188 - scaled_graph_loss: 0.0134 - val_loss: 1.5073 - val_accuracy: 0.4294\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.4195 - accuracy: 0.4244 - scaled_graph_loss: 0.0147 - val_loss: 1.4992 - val_accuracy: 0.4344\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.4485 - accuracy: 0.3930 - scaled_graph_loss: 0.0153 - val_loss: 1.4914 - val_accuracy: 0.4363\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4293 - accuracy: 0.4114 - scaled_graph_loss: 0.0150 - val_loss: 1.4843 - val_accuracy: 0.4437\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.4125 - accuracy: 0.4077 - scaled_graph_loss: 0.0161 - val_loss: 1.4773 - val_accuracy: 0.4488\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.4435 - accuracy: 0.3653 - scaled_graph_loss: 0.0150 - val_loss: 1.4707 - val_accuracy: 0.4524\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.3790 - accuracy: 0.4317 - scaled_graph_loss: 0.0166 - val_loss: 1.4646 - val_accuracy: 0.4575\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3577 - accuracy: 0.4410 - scaled_graph_loss: 0.0160 - val_loss: 1.4581 - val_accuracy: 0.4589\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3484 - accuracy: 0.4502 - scaled_graph_loss: 0.0156 - val_loss: 1.4515 - val_accuracy: 0.4612\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.3800 - accuracy: 0.4225 - scaled_graph_loss: 0.0172 - val_loss: 1.4448 - val_accuracy: 0.4603\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3223 - accuracy: 0.4465 - scaled_graph_loss: 0.0168 - val_loss: 1.4389 - val_accuracy: 0.4626\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.3543 - accuracy: 0.4188 - scaled_graph_loss: 0.0179 - val_loss: 1.4327 - val_accuracy: 0.4672\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.3384 - accuracy: 0.4465 - scaled_graph_loss: 0.0170 - val_loss: 1.4273 - val_accuracy: 0.4672\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3115 - accuracy: 0.4502 - scaled_graph_loss: 0.0182 - val_loss: 1.4214 - val_accuracy: 0.4686\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.3407 - accuracy: 0.4465 - scaled_graph_loss: 0.0187 - val_loss: 1.4161 - val_accuracy: 0.4700\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.3010 - accuracy: 0.4723 - scaled_graph_loss: 0.0180 - val_loss: 1.4108 - val_accuracy: 0.4741\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.2919 - accuracy: 0.4871 - scaled_graph_loss: 0.0180 - val_loss: 1.4048 - val_accuracy: 0.4801\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3062 - accuracy: 0.4834 - scaled_graph_loss: 0.0188 - val_loss: 1.3985 - val_accuracy: 0.4866\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.3054 - accuracy: 0.4815 - scaled_graph_loss: 0.0186 - val_loss: 1.3928 - val_accuracy: 0.4903\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.2826 - accuracy: 0.4594 - scaled_graph_loss: 0.0203 - val_loss: 1.3878 - val_accuracy: 0.4954\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.3139 - accuracy: 0.4723 - scaled_graph_loss: 0.0194 - val_loss: 1.3828 - val_accuracy: 0.5032\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 1.3102 - accuracy: 0.4631 - scaled_graph_loss: 0.0190 - val_loss: 1.3793 - val_accuracy: 0.5032\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.2570 - accuracy: 0.4963 - scaled_graph_loss: 0.0165 - val_loss: 1.3758 - val_accuracy: 0.5069\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 1.2712 - accuracy: 0.4815 - scaled_graph_loss: 0.0178 - val_loss: 1.3724 - val_accuracy: 0.5069\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.2644 - accuracy: 0.4852 - scaled_graph_loss: 0.0184 - val_loss: 1.3699 - val_accuracy: 0.5088\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 1.2787 - accuracy: 0.4742 - scaled_graph_loss: 0.0193 - val_loss: 1.3673 - val_accuracy: 0.5111\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.2355 - accuracy: 0.5037 - scaled_graph_loss: 0.0189 - val_loss: 1.3649 - val_accuracy: 0.5148\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 1.2163 - accuracy: 0.4926 - scaled_graph_loss: 0.0203 - val_loss: 1.3626 - val_accuracy: 0.5152\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 1.2352 - accuracy: 0.5277 - scaled_graph_loss: 0.0184 - val_loss: 1.3604 - val_accuracy: 0.5166\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 1.2404 - accuracy: 0.5111 - scaled_graph_loss: 0.0194 - val_loss: 1.3584 - val_accuracy: 0.5157\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.2191 - accuracy: 0.5351 - scaled_graph_loss: 0.0179 - val_loss: 1.3553 - val_accuracy: 0.5175\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.2170 - accuracy: 0.5185 - scaled_graph_loss: 0.0198 - val_loss: 1.3528 - val_accuracy: 0.5203\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.1939 - accuracy: 0.5554 - scaled_graph_loss: 0.0194 - val_loss: 1.3514 - val_accuracy: 0.5235\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 1.1988 - accuracy: 0.5535 - scaled_graph_loss: 0.0192 - val_loss: 1.3502 - val_accuracy: 0.5226\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.2125 - accuracy: 0.5240 - scaled_graph_loss: 0.0204 - val_loss: 1.3480 - val_accuracy: 0.5240\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.2072 - accuracy: 0.5258 - scaled_graph_loss: 0.0207 - val_loss: 1.3438 - val_accuracy: 0.5272\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.1958 - accuracy: 0.5332 - scaled_graph_loss: 0.0217 - val_loss: 1.3399 - val_accuracy: 0.5295\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.1912 - accuracy: 0.5443 - scaled_graph_loss: 0.0215 - val_loss: 1.3364 - val_accuracy: 0.5360\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1828 - accuracy: 0.5332 - scaled_graph_loss: 0.0187 - val_loss: 1.3328 - val_accuracy: 0.5365\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.1509 - accuracy: 0.5683 - scaled_graph_loss: 0.0214 - val_loss: 1.3294 - val_accuracy: 0.5379\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.1886 - accuracy: 0.5295 - scaled_graph_loss: 0.0207 - val_loss: 1.3272 - val_accuracy: 0.5402\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1574 - accuracy: 0.5590 - scaled_graph_loss: 0.0194 - val_loss: 1.3252 - val_accuracy: 0.5411\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.1286 - accuracy: 0.5683 - scaled_graph_loss: 0.0202 - val_loss: 1.3220 - val_accuracy: 0.5416\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1696 - accuracy: 0.5646 - scaled_graph_loss: 0.0217 - val_loss: 1.3193 - val_accuracy: 0.5439\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1463 - accuracy: 0.5609 - scaled_graph_loss: 0.0229 - val_loss: 1.3179 - val_accuracy: 0.5443\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1474 - accuracy: 0.5701 - scaled_graph_loss: 0.0239 - val_loss: 1.3171 - val_accuracy: 0.5462\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.1449 - accuracy: 0.5627 - scaled_graph_loss: 0.0220 - val_loss: 1.3157 - val_accuracy: 0.5503\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.0949 - accuracy: 0.5904 - scaled_graph_loss: 0.0201 - val_loss: 1.3144 - val_accuracy: 0.5485\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.1434 - accuracy: 0.5590 - scaled_graph_loss: 0.0229 - val_loss: 1.3133 - val_accuracy: 0.5494\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.1165 - accuracy: 0.5793 - scaled_graph_loss: 0.0229 - val_loss: 1.3118 - val_accuracy: 0.5508\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.1318 - accuracy: 0.5738 - scaled_graph_loss: 0.0218 - val_loss: 1.3104 - val_accuracy: 0.5517\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.0951 - accuracy: 0.5959 - scaled_graph_loss: 0.0222 - val_loss: 1.3097 - val_accuracy: 0.5517\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1081 - accuracy: 0.5867 - scaled_graph_loss: 0.0227 - val_loss: 1.3110 - val_accuracy: 0.5540\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1160 - accuracy: 0.5904 - scaled_graph_loss: 0.0223 - val_loss: 1.3118 - val_accuracy: 0.5531\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.1180 - accuracy: 0.5775 - scaled_graph_loss: 0.0222 - val_loss: 1.3131 - val_accuracy: 0.5531\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.0950 - accuracy: 0.5886 - scaled_graph_loss: 0.0221 - val_loss: 1.3133 - val_accuracy: 0.5536\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 1.0579 - accuracy: 0.5941 - scaled_graph_loss: 0.0237 - val_loss: 1.3100 - val_accuracy: 0.5554\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 1.0761 - accuracy: 0.6310 - scaled_graph_loss: 0.0232 - val_loss: 1.3087 - val_accuracy: 0.5559\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 1.1181 - accuracy: 0.5664 - scaled_graph_loss: 0.0226 - val_loss: 1.3092 - val_accuracy: 0.5563\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1272 - accuracy: 0.5683 - scaled_graph_loss: 0.0249 - val_loss: 1.3108 - val_accuracy: 0.5586\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 1.1042 - accuracy: 0.5978 - scaled_graph_loss: 0.0234 - val_loss: 1.3083 - val_accuracy: 0.5605\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 1.0331 - accuracy: 0.6162 - scaled_graph_loss: 0.0243 - val_loss: 1.3051 - val_accuracy: 0.5623\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 1.1293 - accuracy: 0.5867 - scaled_graph_loss: 0.0221 - val_loss: 1.3032 - val_accuracy: 0.5633\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 1.1063 - accuracy: 0.5923 - scaled_graph_loss: 0.0212 - val_loss: 1.3029 - val_accuracy: 0.5633\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 1.0163 - accuracy: 0.6310 - scaled_graph_loss: 0.0233 - val_loss: 1.3027 - val_accuracy: 0.5660\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 1.0940 - accuracy: 0.6033 - scaled_graph_loss: 0.0235 - val_loss: 1.3033 - val_accuracy: 0.5669\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 1.0457 - accuracy: 0.6236 - scaled_graph_loss: 0.0224 - val_loss: 1.3019 - val_accuracy: 0.5683\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 1.0357 - accuracy: 0.6162 - scaled_graph_loss: 0.0253 - val_loss: 1.2998 - val_accuracy: 0.5734\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 1.0523 - accuracy: 0.6052 - scaled_graph_loss: 0.0224 - val_loss: 1.2990 - val_accuracy: 0.5725\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 1.0581 - accuracy: 0.6033 - scaled_graph_loss: 0.0252 - val_loss: 1.3008 - val_accuracy: 0.5725\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 1.0418 - accuracy: 0.6531 - scaled_graph_loss: 0.0253 - val_loss: 1.3012 - val_accuracy: 0.5716\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 1.0691 - accuracy: 0.6181 - scaled_graph_loss: 0.0234 - val_loss: 1.3006 - val_accuracy: 0.5725\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 1.0168 - accuracy: 0.6384 - scaled_graph_loss: 0.0238 - val_loss: 1.3034 - val_accuracy: 0.5706\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 1.0461 - accuracy: 0.6107 - scaled_graph_loss: 0.0220 - val_loss: 1.3098 - val_accuracy: 0.5669\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 1.0429 - accuracy: 0.6273 - scaled_graph_loss: 0.0240 - val_loss: 1.3135 - val_accuracy: 0.5660\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.9731 - accuracy: 0.6587 - scaled_graph_loss: 0.0238 - val_loss: 1.3139 - val_accuracy: 0.5683\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.9832 - accuracy: 0.6624 - scaled_graph_loss: 0.0259 - val_loss: 1.3126 - val_accuracy: 0.5688\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.9930 - accuracy: 0.6476 - scaled_graph_loss: 0.0247 - val_loss: 1.3108 - val_accuracy: 0.5725\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 1.0107 - accuracy: 0.6218 - scaled_graph_loss: 0.0232 - val_loss: 1.3082 - val_accuracy: 0.5743\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.9550 - accuracy: 0.6439 - scaled_graph_loss: 0.0234 - val_loss: 1.3043 - val_accuracy: 0.5808\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 1.0061 - accuracy: 0.6162 - scaled_graph_loss: 0.0251 - val_loss: 1.3007 - val_accuracy: 0.5845\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 1.0057 - accuracy: 0.6236 - scaled_graph_loss: 0.0246 - val_loss: 1.2999 - val_accuracy: 0.5840\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9844 - accuracy: 0.6439 - scaled_graph_loss: 0.0234 - val_loss: 1.2997 - val_accuracy: 0.5859\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9781 - accuracy: 0.6458 - scaled_graph_loss: 0.0261 - val_loss: 1.3001 - val_accuracy: 0.5868\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 1.0391 - accuracy: 0.6070 - scaled_graph_loss: 0.0245 - val_loss: 1.3001 - val_accuracy: 0.5863\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 1.0058 - accuracy: 0.6421 - scaled_graph_loss: 0.0253 - val_loss: 1.3031 - val_accuracy: 0.5854\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.9445 - accuracy: 0.6697 - scaled_graph_loss: 0.0235 - val_loss: 1.3049 - val_accuracy: 0.5849\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9833 - accuracy: 0.6605 - scaled_graph_loss: 0.0259 - val_loss: 1.3081 - val_accuracy: 0.5854\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9941 - accuracy: 0.6568 - scaled_graph_loss: 0.0241 - val_loss: 1.3110 - val_accuracy: 0.5854\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.9927 - accuracy: 0.6402 - scaled_graph_loss: 0.0266 - val_loss: 1.3125 - val_accuracy: 0.5868\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9782 - accuracy: 0.6531 - scaled_graph_loss: 0.0238 - val_loss: 1.3114 - val_accuracy: 0.5886\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9561 - accuracy: 0.6587 - scaled_graph_loss: 0.0259 - val_loss: 1.3123 - val_accuracy: 0.5868\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.9698 - accuracy: 0.6328 - scaled_graph_loss: 0.0252 - val_loss: 1.3122 - val_accuracy: 0.5863\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9826 - accuracy: 0.6568 - scaled_graph_loss: 0.0256 - val_loss: 1.3134 - val_accuracy: 0.5877\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.9486 - accuracy: 0.6624 - scaled_graph_loss: 0.0262 - val_loss: 1.3163 - val_accuracy: 0.5891\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.9411 - accuracy: 0.6421 - scaled_graph_loss: 0.0294 - val_loss: 1.3165 - val_accuracy: 0.5896\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.9299 - accuracy: 0.6550 - scaled_graph_loss: 0.0246 - val_loss: 1.3194 - val_accuracy: 0.5886\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.9345 - accuracy: 0.6753 - scaled_graph_loss: 0.0269 - val_loss: 1.3203 - val_accuracy: 0.5896\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.9286 - accuracy: 0.6697 - scaled_graph_loss: 0.0253 - val_loss: 1.3215 - val_accuracy: 0.5886\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.9240 - accuracy: 0.6716 - scaled_graph_loss: 0.0289 - val_loss: 1.3207 - val_accuracy: 0.5905\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.9320 - accuracy: 0.6716 - scaled_graph_loss: 0.0242 - val_loss: 1.3196 - val_accuracy: 0.5923\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.9838 - accuracy: 0.6439 - scaled_graph_loss: 0.0278 - val_loss: 1.3222 - val_accuracy: 0.5919\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.9558 - accuracy: 0.6531 - scaled_graph_loss: 0.0276 - val_loss: 1.3247 - val_accuracy: 0.5937\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.9417 - accuracy: 0.6476 - scaled_graph_loss: 0.0260 - val_loss: 1.3293 - val_accuracy: 0.5946\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9311 - accuracy: 0.6605 - scaled_graph_loss: 0.0242 - val_loss: 1.3361 - val_accuracy: 0.5928\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9177 - accuracy: 0.6790 - scaled_graph_loss: 0.0261 - val_loss: 1.3394 - val_accuracy: 0.5937\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9269 - accuracy: 0.6661 - scaled_graph_loss: 0.0244 - val_loss: 1.3407 - val_accuracy: 0.5914\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9322 - accuracy: 0.6642 - scaled_graph_loss: 0.0268 - val_loss: 1.3424 - val_accuracy: 0.5905\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.8964 - accuracy: 0.6974 - scaled_graph_loss: 0.0268 - val_loss: 1.3426 - val_accuracy: 0.5914\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9593 - accuracy: 0.6458 - scaled_graph_loss: 0.0248 - val_loss: 1.3405 - val_accuracy: 0.5919\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.9000 - accuracy: 0.6679 - scaled_graph_loss: 0.0268 - val_loss: 1.3430 - val_accuracy: 0.5960\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9122 - accuracy: 0.6808 - scaled_graph_loss: 0.0247 - val_loss: 1.3449 - val_accuracy: 0.5979\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.9074 - accuracy: 0.6716 - scaled_graph_loss: 0.0238 - val_loss: 1.3446 - val_accuracy: 0.5993\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9025 - accuracy: 0.6900 - scaled_graph_loss: 0.0268 - val_loss: 1.3469 - val_accuracy: 0.5993\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.8493 - accuracy: 0.7196 - scaled_graph_loss: 0.0270 - val_loss: 1.3498 - val_accuracy: 0.5983\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9285 - accuracy: 0.6568 - scaled_graph_loss: 0.0273 - val_loss: 1.3533 - val_accuracy: 0.5983\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.8879 - accuracy: 0.6827 - scaled_graph_loss: 0.0283 - val_loss: 1.3535 - val_accuracy: 0.6002\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9217 - accuracy: 0.6679 - scaled_graph_loss: 0.0266 - val_loss: 1.3549 - val_accuracy: 0.5997\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.8804 - accuracy: 0.6919 - scaled_graph_loss: 0.0274 - val_loss: 1.3569 - val_accuracy: 0.5997\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9178 - accuracy: 0.6568 - scaled_graph_loss: 0.0259 - val_loss: 1.3607 - val_accuracy: 0.6002\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9175 - accuracy: 0.6808 - scaled_graph_loss: 0.0270 - val_loss: 1.3648 - val_accuracy: 0.5983\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.8565 - accuracy: 0.7177 - scaled_graph_loss: 0.0253 - val_loss: 1.3728 - val_accuracy: 0.5997\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.8599 - accuracy: 0.6863 - scaled_graph_loss: 0.0259 - val_loss: 1.3816 - val_accuracy: 0.5979\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9096 - accuracy: 0.6661 - scaled_graph_loss: 0.0271 - val_loss: 1.3838 - val_accuracy: 0.5974\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.9209 - accuracy: 0.6845 - scaled_graph_loss: 0.0255 - val_loss: 1.3820 - val_accuracy: 0.5970\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.8774 - accuracy: 0.6919 - scaled_graph_loss: 0.0287 - val_loss: 1.3784 - val_accuracy: 0.5974\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.8557 - accuracy: 0.7066 - scaled_graph_loss: 0.0272 - val_loss: 1.3773 - val_accuracy: 0.5988\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.9321 - accuracy: 0.6661 - scaled_graph_loss: 0.0293 - val_loss: 1.3790 - val_accuracy: 0.5960\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.8449 - accuracy: 0.7048 - scaled_graph_loss: 0.0302 - val_loss: 1.3823 - val_accuracy: 0.5960\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.8637 - accuracy: 0.6937 - scaled_graph_loss: 0.0286 - val_loss: 1.3838 - val_accuracy: 0.5956\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.8884 - accuracy: 0.6734 - scaled_graph_loss: 0.0265 - val_loss: 1.3872 - val_accuracy: 0.5956\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.8673 - accuracy: 0.6845 - scaled_graph_loss: 0.0275 - val_loss: 1.3922 - val_accuracy: 0.5965\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.8873 - accuracy: 0.6679 - scaled_graph_loss: 0.0269 - val_loss: 1.3979 - val_accuracy: 0.5970\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.8896 - accuracy: 0.6900 - scaled_graph_loss: 0.0297 - val_loss: 1.3991 - val_accuracy: 0.5979\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.9055 - accuracy: 0.6845 - scaled_graph_loss: 0.0294 - val_loss: 1.3931 - val_accuracy: 0.5993\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.8845 - accuracy: 0.6827 - scaled_graph_loss: 0.0273 - val_loss: 1.3889 - val_accuracy: 0.6002\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.8574 - accuracy: 0.6919 - scaled_graph_loss: 0.0262 - val_loss: 1.3848 - val_accuracy: 0.6039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79966f3d90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_reg_model.fit(myTrain.batch(128), epochs=200, verbose=1, validation_data=myTest.batch(128),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/regularization')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b632d4f284bbe77588fa149b6cb67b77182ce71d42208176a727bc04a09d6e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
